# Interaction Humain-Machine Multimodale / Multimodal Human-Machine Interaction
## Interaction vocale / vocal interaction
* **TP1/Tutorial 1** - [Interaction vocale](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/TP1_interaction_vocale.pdf) / [Vocal Interaction](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/T1_vocal_interaction.pdf) (2021)
   * **Les outils utilisés dans le TP / tools used in this tutorial** : Agent de reconnaissance vocale / Speech Recognizer agent [sra5](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Code/sra5.zip), agent de synthèse vocale / speech Synthesis agent [ppilot5 v 3.2](https://github.com/truillet/ivy/blob/master/agents/ppilot5_3.2.zip), outil de supervision ivy / ivy monitoring tool [Probe] (https://github.com/truillet/ivy/blob/master/code/Probe.zip) ou / or [visionneur](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Outils/visionneur_1_2.zip)
  * **[GrXML pour SAPI 5](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/GrXML.pdf)**
  
_Exemple de code Processing permettant l'affichage de la reconnaissance vocale et l'envoi du résultat vers la synthèse vocale / Example of Processing code allowing the text ouptut of speech recognition and sending the result to TTS_ : **[vocal_ivy](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Code/vocal_ivy.zip)**

## Interaction gestuelle / gesture interaction
* **TP2/Tutorial 2** - [Interaction gestuelle](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/TP2_InteractionGestuelle.pdf) / [Gesture Interaction](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/T2_gesture_interaction.pdf) (2021)

_Exemple de code Processing permettant l'enregistrement de formes dessinées à l'écran / Example of Processing code for recording shapes drawn on the screen_ : **[Enregistrement Forme](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Code/Enregistrement_Forme.zip)**

_Autres ressources / Other resources_
   * **OneDollarIvy** (implémentation de l'algorithme du [$1 Recognizer](http://faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf)) [code source](https://github.com/truillet/OneDollarIvy)
   * **ICAR** (implémentation de l'algorithme de [Rubine](http://reports-archive.adm.cs.cmu.edu/anon/itc/CMU-ITC-099.pdf)) [code source](https://github.com/truillet/icar), [fichier jar](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Outils/icar.1.2.zip) et [documentation](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Outils/icar.pdf)

## Fusion Multimodale / Multimodal Fusion
* **TP3-5/Tutorial 3 to 5** - [Moteur de Fusion](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/TP3-5_Projet_Multimodal.pdf) / [Multimodal Engine](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/T3-5_multimodal_interaction.pdf) (2021)

_Exemple de code Processing permettant la gestion de formes géométriques / Example of Processing code for rmanipulating different shapes_ :_ : **[Palette](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Code/Palette.zip)**

[<img src="https://img.youtube.com/vi/RyBEUyEtxQo/0.jpg" width=250 alt="Put That There">](https://youtu.be/RyBEUyEtxQo)

[R. Bolt, "Put-That-There": Voice and Gesture at the Graphics Interface, SIGGRAPH 1980](https://www.media.mit.edu/speech/papers/1980/bolt_SIGGRAPH80_put-that-there.pdf)

[Sh. Oviatt, Ten Myths on Multimodal Interaction, Communication of the ACM, volume 42, Issue 11, November 1999](https://dl.acm.org/doi/10.1145/319382.319398)

<!--
## Interaction Multimodale & Accessibilité
* **TP6** - [Interaction &amp; Handicap](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/TP6_Interaction_et_Handicap.pdf) (2020)

_Exemple de code p5js permettant l'usage de la reconnaissance vocale_ : **[p5.js](https://github.com/truillet/upssitech/blob/master/SRI/3A/IHM/TP/Outils/p5js.zip)**

[Accessibility Cheatsheet](https://moritzgiessmann.de/accessibility-cheatsheet)
-->
